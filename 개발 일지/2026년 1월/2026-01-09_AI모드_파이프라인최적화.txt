================================================================
NotioClass 개발 일지 - 2026년 1월 9일
================================================================

작업 내용: AI 모드 선택 기능 및 파이프라인 최적화


----------------------------------------------------------------
1. AI 모드 선택 기능 구현
----------------------------------------------------------------

배경:
  - 기존 필기 정리 시간: GPT-5.2 기준 ~107초
  - 사용자가 속도/품질 중 선택할 수 있도록 개선 필요

구현 내용:

[백엔드]
  - User 모델에 ai_mode 컬럼 추가 (String, fast/quality)
  - get_default_model() 함수 수정
    - fast 모드: GPT-5-mini (~70초 목표)
    - quality 모드: 플랜별 최고 모델
      - Free: GPT-5-mini
      - Basic: GPT-5
      - Pro: GPT-5.2
  - GET/PATCH /me/ai-mode API 추가

[프론트엔드]
  - 업로드 화면에 AI 모드 선택 UI 추가
  - 빠른 모드(⚡) / 품질 모드(✨) 토글

수정된 파일:
  - backend/app/models/user.py
  - backend/app/api/auth.py
  - backend/app/schemas/auth.py
  - mobile/app/(tabs)/upload.tsx
  - mobile/services/api.ts


----------------------------------------------------------------
2. OpenAI AsyncOpenAI 전환 (서버 블로킹 해결)
----------------------------------------------------------------

문제:
  - 동기 OpenAI 클라이언트 사용 시 서버 전체 블로킹
  - AI 처리 중 polling 요청에 응답 불가 (Network Error)
  - 처리 시간 2분으로 증가

해결:
  - from openai import OpenAI → from openai import AsyncOpenAI
  - 모든 API 호출에 await 추가
  - 처리 중에도 다른 요청 응답 가능해짐

수정된 파일:
  - backend/app/services/ai_service.py


----------------------------------------------------------------
3. 서버 워커 증가
----------------------------------------------------------------

변경 내용:
  - uvicorn --workers 1 → --workers 2
  - 처리 중에도 다른 워커가 요청 처리 가능

수정된 파일:
  - backend/Procfile
  - backend/Dockerfile


----------------------------------------------------------------
4. AI 파이프라인 속도 분석
----------------------------------------------------------------

현재 구조 (3번 API 호출):
  - Step 0: OCR 정제 (GPT-5-mini) ~35초
  - Step 1: 구조 분석 (GPT-5-mini) ~35초
  - Step 2: 콘텐츠 생성 (GPT-5-mini) ~35초
  - 총합: ~105-110초

문제점:
  - GPT-5-mini 사용해도 여전히 ~110초 소요
  - 3번의 순차 API 호출이 병목

TODO (다음 세션):
  - Step 1 + Step 2 합치기 (API 호출 3회 → 2회)
  - 구조 분석하면서 동시에 콘텐츠 생성
  - 예상 효과: ~110초 → ~70초
  - 품질 유지 필수


----------------------------------------------------------------
5. 기타 변경사항
----------------------------------------------------------------

  - Step 0 모델: GPT-5-nano → GPT-5-mini 변경
  - 디버그 로그 추가: ai_mode, model 정보 출력
  - polling 설정 복원: MAX_RETRIES=5, BASE_DELAY=800ms


----------------------------------------------------------------
테스트 결과
----------------------------------------------------------------

  - AI 모드: fast (GPT-5-mini)
  - 처리 시간: ~97초 ~ 110초 (내용량에 따라 변동)
  - Network Error: 워커 2개로 개선됨
  - 목표 달성 여부: 부분 달성 (Step 합치기 필요)


================================================================
